# 《Image-to-Image Translation with Conditional Adversarial NetWorks》
加里福利亚大学在CVPR 2017上发表的一篇论文，讲的是如何用条件生成对抗网络实现图像到图像的转换任务

**原文链接：https://arxiv.org/abs/1611.07004**  

**项目主页：https://phillipi.github.io/pix2pix/** （其中包含了PyTorch、Tensorflow等主流框架的代码实现）

![Figure 1](https://img-blog.csdnimg.cn/20210310110036603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzOTA4MTgy,size_16,color_FFFFFF,t_70)
Figure 1：图像、视觉中很多问题都涉及到将一副图像转换为另一幅图像（Image-to-Image Translation Problem），这些问题通常都使用特定的方法来解决，不存在一个通用的方法。但图像转换问题本质上其实就是像素到像素的映射问题；条件对抗网络对于此类问题是一种通用的解决方案，它似乎能很好地解决各种各样的此类问题。如上图所示，使用CGAN可以实现语义/标签到真实图片、灰度图到彩色图、航空图到地图、白天到黑夜、线稿图到实物图的转换。使用完全一样的网络结构和目标函数，仅更换不同的训练数据集就能分别实现以上的任务。

# 摘要
我们研究将条件生成对抗网络作为图像转换问题的通用解决方案。该网络不仅可以学习输入图像到输出图像的映射关系，还能够学习用于训练映射关系的loss函数。这使得我们可以使用同一种方法来解决那些传统上需要各种形式loss函数的问题。我们证明了该方法可以有效实现下列任务：从标签图合成相片，从线稿图重构对象，给图片上色等。实际上，自从与本文相关的pix2pix软件发布以来，大量的互联网用户（其中许多是艺术家）已经发布了他们对我们系统的实验，从而进一步证明了该系统的广泛适用性和易用性，而无需进行参数调整 。 As a community，我们不再需要手动设计映射函数，而且本研究表明，我们即使不手动设计loss函数，也能达到合理的结果。

# 1.介绍
在图像处理、计算机图形学和计算机视觉领域，很多问题都可以认为是将一张输入图片“转换”成相对应的输出图片。一个场景可以被渲染为RGB图像，梯度域，边缘图或语义图等。与自动语言翻译类似，我们将自动图像到图像翻译定义为：在给定足够的训练数据的情况下，将场景的一种可能表示转换为另一种场景的任务（请参见图1）。传统上，每一项任务都由单独用途机制来处理的（例如[16、25、20、9、11、53、33、39、18、58、62]），但无非都是像素到像素的映射。本文的目标是为所有这些问题建立一个共同的框架。

同行已经在这个方向取得了重大的进步，CNNs逐渐成为解决各种图像预测问题的主力。CNNs通过学习使loss函数最小化（评估结果质量的目标），尽管学习过程是自动化的，但仍需要投入大量人力来设计有效的loss函数。换句话说，我们仍然需要告诉CNN我们希望将什么最小化。但是我们必须得和Midas一样谨慎“设计”我们期望的东西！如果我们采用了不成熟的方法，要求CNN最小化预测图像和真值图像之间的欧氏距离，那么这将会产生模糊的结果。这是因为欧式距离是通过将所有输出平均来最小化的，这将会产生模糊的结果。为了得到能够使CNN输出锐利，真实的图像，如何设计loss函数是一个开放性的且需要专业知识的问题。

相对的，如果我们只需要指定一个高级的目标，比如“产生难以和真实图片分辨的输出”，然后自动学习一个适合目标的loss函数，这就非常令人满意了。幸运的是，这正是最近提出的生成对抗网络GANs所做的事。GANs学习的是一个区分真实和伪造图像的loss函数，同时训练一个生成模型来最小化这个loss。模糊的图像将无法被容忍，因为它们看起来明显是伪造的图像。由于GANs学习的是适应于数据的loss，因此可以将GANs应用到大量的不同任务中去，而传统方法可能针对不同任务需要不同类型的loss函数。

本文中，我们研究CGANs（具有条件约束的对抗生成网络），和GANs从数据中学习一个生成模型一样，CGANs学习一个条件生成模型。这使CGANs适用于图像转换问题，我们在输入图片上设置条件约束，得到相应的输出图像。

GANs在最近两年得到了广泛的研究，本文研究的许多技术在之前就已经提出了。尽管如此，之前的论文都是关注特定的应用，而cGANs作为图像转换问题的通用方法的有效性却仍然是不清楚的。我们主要的贡献是阐释了cGANs在很多问题上都能产生合理的结果。第二个贡献是提出了一个简单有效的框架，并分析了几种重要结构选择的效果。代码可在https://github.com/phillipi/pix2pix上找到。

# 2.相关工作

图像到图像的转换问题通常被表述为逐像素分类或回归(例如，[39,58,28,35,62])。这些公式将输出空间视为非结构化的，因为给定输入图像，每个输出像素都被认为是有条件独立于所有其他像素的。相反，有条件的甘斯学会了结构性损失。结构损失惩罚输出的联合配置。大量文献考虑了这类损失，方法包括条件随field [10]， SSIM metric [56]， feature matching [15]， non - parametric losses [37]， convolutional伪先验[57]，以及基于匹配协方差统计量[30]的损失。有条件氮化镓的不同之处在于它的损失是可以学习的，并且理论上可以惩罚输出和目标之间任何可能的结构差异。

![Figure 2](https://img-blog.csdnimg.cn/20210310114515741.png)
Figure 2：训练CGAN来完成映射：轮廓图→照片。 鉴别器，D，学习伪造图像（由生成器合成）和真实元组 {轮廓图，照片}之间进行分类。 生成器，G，学习“欺骗”鉴别器。与无条件GAN不同，生成器和判别器都需要观测输入的边缘映射。

我们不是第一个在条件设置中应用GANs的人。先前的和并发的作品将GANs限定在离散的标签[41,23,13]，文本[46]，实际上，还有图像上。图像条件模型处理了法线映射[55]图像预测、未来帧预测[40]、产品照片生成[59]和稀疏注释图像生成[31,48](针对同一问题的自回归方法c.f.[47])。其他几篇论文也将GAN用于图像到图像的映射，但只是无条件地应用GAN，依赖于其他术语(如L2回归)来迫使输出取决于输入。这些论文在修复[43]、未来状态预测[64]、用户约束引导下的图像处理[65]、样式转移[38]、超分辨率[36]等方面取得了令人印象深刻的成果。每一种方法都是为特定的应用量身定制的。我们的框架的不同之处在于没有什么是特定于应用程序的。这使得我们的设置比大多数其他设置要简单得多。

我们的方法也不同于之前的工作在几个架构选择的发生器和鉴别器。与以往的工作不同，我们的生成器使用了基于U-Net的架构[50]，而我们的鉴别器使用了PatchGAN分类器，它是只在图像Patch的尺度上惩罚的结构。以前在[38]中提出了一个类似的PatchGAN架构来捕获本地样式统计信息。在这里，我们展示了这种方法在更广泛的问题上是有效的，并且我们调查了改变Patch Size的影响。

# 3.方法
GANs是生成式模型，学习从随机噪声向量z到输出图像y, G: (z,y)[24]的映射。相比之下,有条件的GANs学习从观测到的图像x和随机噪声向量z映射到y, 即G : {x, z} → y，生成器G被训练为产生识别器D不能区分真假的输出，识别器被训练为尽可能好地检测生成器输出的“赝品”。培训过程Figure 2所示。  
